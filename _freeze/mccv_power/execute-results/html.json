{
  "hash": "0c69486a5d25bbc80e1a9b31bd246b8e",
  "result": {
    "markdown": "---\ntitle: \"Estimating Power Using MCCV\"\nformat:\n  html:\n    code-fold: true\n    code-summary: 'Show The Code'\n---\n\n\nA question of interest often is at what sample size can I detect an effect? MCCV can estimate the power to detect an effect by learning from data at different sample sizes. For example, I may reach a large effect or performance, say 0.8 AUROC, using all subjects. However, can I still reach or get close to 0.8 AUROC at a smaller sample size, say 50% of subjects? This article will show an interactive example of how learning from varying sample sizes yields effects reaching the effect using all the data.\n\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-1_77680a86922b8429eba902f0ab955b60'}\n\n```{.python .cell-code}\nimport numpy as np\nN=100\nZ1 = np.random.beta(2.5,3.5,size=N)\nZ2 = np.random.beta(3.5,2.5,size=N)\nZ = np.concatenate([Z1,Z2])\n\nimport scipy as sc\nY = np.concatenate([np.repeat(0,N),np.repeat(1,N)])\n\nimport pandas as pd\ndf = pd.DataFrame(data={'Y' : Y,'Z' : Z})\ndf.index.name = 'pt'\n```\n:::\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-2_9db30d81c6f05f07d3449c891ff84da5'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndf <- tibble::tibble(\n    Y = reticulate::py$Y,\n    Z = reticulate::py$Z\n)\ndf[['Y']] <- factor(df$Y,levels=c(0,1))\n\ndf %>% \n    ggplot(aes(Y,Z)) +\n    geom_boxplot(outlier.size = NA,alpha=0,linewidth=2) +\n    geom_point(position = position_jitter(width = .2),pch=21,fill='gray',size=3) +\n    labs(x = \"Response\",y=\"Predictor\") +\n    theme_bw(base_size = 16)\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-3_9f4e201b3fdc6e19d0cfdc2ba3a73b88'}\n\n```{.python .cell-code}\nimport mccv\n\nperf_dfs = []\nfor ts in [.1,.2,.3,.4,.5,.6,.7,.8]:\n    mccv_obj = mccv.mccv(num_bootstraps=200,n_jobs=4)\n    mccv_obj.test_size = ts\n    mccv_obj.set_X(df[['Z']])\n    mccv_obj.set_Y(df[['Y']])\n    mccv_obj.run_mccv()\n    perf_df = mccv_obj.mccv_data['Performance']\n    perf_df.insert(len(perf_df.columns),'training_size',1-ts)\n    perf_df.insert(len(perf_df.columns),'test_size',ts)\n    perf_dfs.append(perf_df)\n```\n:::\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-4_3c612063f27a717152d60ebdb22ec86d'}\n\n```{.r .cell-code}\nreticulate::py$perf_dfs %>% \n    bind_rows() %>% \n    ggplot(aes(factor(training_size),value)) +\n    geom_boxplot(outlier.size = NA,alpha=0,linewidth=2) +\n    geom_point(position = position_jitter(width = .2),pch=21,fill='gray',size=3) +\n    scale_x_discrete(\n        labels = function(x)paste0(as.double(x)*100,\"%\")\n    ) +\n    labs(x = \"Sample Size for MCCV Training\",y=\"AUROC\",caption=paste0(\n        \"As we increase our sample size for learning,\\n\",\n        \"performance increases as expected,\\n\",\n        \"but so does AUROC variability\")) +\n    theme_bw(base_size = 16)\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThe below is an example where the AUROC vriability actually shows a decreased overall performance:\n\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-5_447e1dfc489bcc365fa75e0f90ccd141'}\n\n```{.python .cell-code}\nimport numpy as np\nN=100\nZ1 = np.random.beta(2,4,size=N)\nZ2 = np.random.beta(8,6,size=N)\nZ = np.concatenate([Z1,Z2])\n\nimport scipy as sc\nY = np.concatenate([np.repeat(0,N),np.repeat(1,N)])\n\nimport pandas as pd\ndf = pd.DataFrame(data={'Y' : Y,'Z' : Z})\ndf.index.name = 'pt'\n```\n:::\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-6_0da1af78aa269dd30dca1e731d1b7eeb'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndf <- tibble::tibble(\n    Y = reticulate::py$Y,\n    Z = reticulate::py$Z\n)\ndf[['Y']] <- factor(df$Y,levels=c(0,1))\n\ndf %>% \n    ggplot(aes(Y,Z)) +\n    geom_boxplot(outlier.size = NA,alpha=0,linewidth=2) +\n    geom_point(position = position_jitter(width = .2),pch=21,fill='gray',size=3) +\n    labs(x = \"Response\",y=\"Predictor\") +\n    theme_bw(base_size = 16)\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-7_3cc8abd734fd8ad212ea2bc6114fcb25'}\n\n```{.python .cell-code}\nimport mccv\n\nperf_dfs = []\nfor ts in [.1,.2,.3,.4,.5,.6,.7,.8]:\n    mccv_obj = mccv.mccv(num_bootstraps=200,n_jobs=4)\n    mccv_obj.test_size = ts\n    mccv_obj.set_X(df[['Z']])\n    mccv_obj.set_Y(df[['Y']])\n    mccv_obj.run_mccv()\n    perf_df = mccv_obj.mccv_data['Performance']\n    perf_df.insert(len(perf_df.columns),'training_size',1-ts)\n    perf_df.insert(len(perf_df.columns),'test_size',ts)\n    perf_dfs.append(perf_df)\n```\n:::\n\n::: {.cell hash='mccv_power_cache/html/unnamed-chunk-8_08627e700ccb55ce4f96a9cbf77771fb'}\n\n```{.r .cell-code}\nreticulate::py$perf_dfs %>% \n    bind_rows() %>% \n    ggplot(aes(factor(training_size),value)) +\n    geom_boxplot(outlier.size = NA,alpha=0,linewidth=2) +\n    geom_point(position = position_jitter(width = .2),pch=21,fill='gray',size=3) +\n    scale_x_discrete(\n        labels = function(x)paste0(as.double(x)*100,\"%\")\n    ) +\n    labs(x = \"Sample Size for MCCV Training\",y=\"AUROC\",caption=paste0(\n        \"As we increase our sample size for learning,\\n\",\n        \"performance increases as expected,\\n\",\n        \"but so does AUROC variability that shows decreased overall performance\")) +\n    theme_bw(base_size = 16)\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}