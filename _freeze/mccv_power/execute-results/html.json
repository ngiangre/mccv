{
  "hash": "e177e2d80e27cac5ce692e8dd1a429dc",
  "result": {
    "markdown": "---\ntitle: \"Estimating Power\"\nformat:\n  html:\n    code-fold: true\n    code-summary: 'Show The Code'\n---\n\n\nOne of the advantages of using MCCV is it's data-driven approach. Given data, you can answer questions such as:\n\n1.  How predictive is Y from X?\n2.  Is a certain cut of the data driving the prediction?\n3.  Is there another variable obscuring or influencing the contribution of X in predicting Y?\n\nIn this article I want to illustrate another type of question MCCV can address:\n\n-   How does the prediction of Y by X compare to the prediction by X to a random Y? In other words, what is the power of my data X to predict Y?\n\nI will discuss at the end how the term 'power' is used here in comparison to the statistical and more common form of the term. First, I will show two examples showing the power of X to predict Y.\n\nThis first example shows low power \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nN=100\nX1 = np.random.normal(loc=0,scale=1,size=N)\nX2 = np.random.normal(loc=0.5,scale=1,size=N)\nX = np.concatenate([X1,X2])\nY = np.concatenate([np.repeat(0,N),np.repeat(1,N)])\n\nimport pandas as pd\ndf = pd.DataFrame(data={'Y' : Y,'X' : X})\ndf.index.name = 'pt'\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndf <- reticulate::py$df\n\ndf[['Y']] <- factor(df$Y,levels=c(0,1))\n\ndf %>% \n    ggplot(aes(Y,X)) +\n    geom_boxplot(outlier.size = NA,alpha=0,linewidth=2) +\n    geom_point(position = position_jitter(width = .2),pch=21,fill='gray',size=3) +\n    labs(x = \"Response\",y=\"Predictor\",title = \"Predictor values for Class One are 50% larger on average\") +\n    theme_bw(base_size = 16)\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport mccv\n\nmccv_obj = mccv.mccv(num_bootstraps=200,n_jobs=4)\nmccv_obj.set_X(df[['X']])\nmccv_obj.set_Y(df[['Y']])\nmccv_obj.run_mccv()\nmccv_obj.mccv_data['Feature Importance'].insert(\n    len(mccv_obj.mccv_data['Feature Importance'].columns),\n    'type',\n    'real'\n)\nmccv_obj.mccv_data['Model Learning'].insert(\n    len(mccv_obj.mccv_data['Model Learning'].columns),\n    'type',\n    'real'\n)\nmccv_obj.mccv_data['Patient Predictions'].insert(\n    len(mccv_obj.mccv_data['Patient Predictions'].columns),\n    'type',\n    'real'\n)\nmccv_obj.run_permuted_mccv()\nmccv_obj.mccv_permuted_data['Feature Importance'].insert(\n    len(mccv_obj.mccv_permuted_data['Feature Importance'].columns),\n    'type',\n    'permuted'\n)\nmccv_obj.mccv_permuted_data['Model Learning'].insert(\n    len(mccv_obj.mccv_permuted_data['Model Learning'].columns),\n    'type',\n    'permuted'\n)\nmccv_obj.mccv_permuted_data['Patient Predictions'].insert(\n    len(mccv_obj.mccv_permuted_data['Patient Predictions'].columns),\n    'type',\n    'permuted'\n)\n\nfimp_df = \\\npd.concat([\n    (mccv_obj.mccv_data['Feature Importance'].\n    query('feature==\"X\"').\n    reset_index(drop=True)),\n    (mccv_obj.mccv_permuted_data['Feature Importance'].\n    query('feature==\"X\"').\n    reset_index(drop=True))\n])\nppred_df = \\\npd.concat([\n    (mccv_obj.mccv_data['Patient Predictions'].\n    drop('y_pred',axis=1).\n    reset_index()),\n    (mccv_obj.mccv_permuted_data['Patient Predictions'].\n    reset_index().\n    drop('y_pred',axis=1))\n])\npred_df = \\\npd.concat([\n    (mccv_obj.mccv_data['Model Learning'].\n    reset_index()),\n    (mccv_obj.mccv_permuted_data['Model Learning'].\n    reset_index())\n])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npks <- \n    ks.test(\n    reticulate::py$pred_df %>% \n        filter(type=='real') %>% \n        pull(validation_roc_auc),\n    reticulate::py$pred_df %>% \n        filter(type=='permuted') %>% \n        pull(validation_roc_auc),\n    alternative = 'greater'\n)[['p.value']]\n\npwilcox <- \n    wilcox.test(\n    reticulate::py$pred_df %>% \n        filter(type=='real') %>% \n        pull(validation_roc_auc),\n    reticulate::py$pred_df %>% \n        filter(type=='permuted') %>% \n        pull(validation_roc_auc)\n)[['p.value']]\n\nreticulate::py$pred_df %>% \n    ggplot(aes(validation_roc_auc,fill=type)) +\n    geom_histogram(aes(y=after_stat(count)),alpha=.5,binwidth = .05) +\n    scale_fill_brewer(palette = 'Set1',direction = -1,\n                      guide=guide_legend(title=NULL)) +\n    theme_bw() +\n    scale_x_continuous(\n        breaks=seq(0,1,0.05),\n    ) +\n    labs(x='Validation AUROC from Model Learning',\n         y='Number of Validation AUROC values',\n         caption=paste0('Wilcox p-value = ',scales::scientific(pwilcox,3),'\\n',\n                        'Kolmogorov-Smirnov p-value = ',scales::scientific(pks,3),'\\n',\n                        'Real validation AUROC values are greater than Permuted validation AUROC values'))\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npks <- \n    ks.test(\n    reticulate::py$fimp_df %>% \n        filter(type=='real') %>% \n        pull(importance),\n    reticulate::py$fimp_df %>% \n        filter(type=='permuted') %>% \n        pull(importance)\n)[['p.value']]\n\npwilcox <- \n    wilcox.test(\n    reticulate::py$fimp_df %>% \n        filter(type=='real') %>% \n        pull(importance),\n    reticulate::py$fimp_df %>% \n        filter(type=='permuted') %>% \n        pull(importance)\n)[['p.value']]\n\nreticulate::py$fimp_df %>% \n    ggplot(aes(importance,fill=type)) +\n    geom_histogram(aes(y=after_stat(count)),alpha=.5,binwidth = .2) +\n    scale_fill_brewer(palette = 'Set1',direction = -1,\n                      guide=guide_legend(title=NULL)) +\n    theme_bw() +\n    labs(x='Importance of X in Predicting Y',\n         y='Number of X importance values',\n         caption=paste0('Wilcox p-value = ',scales::scientific(pwilcox,3),'\\n',\n                        'Kolmogorov-Smirnov p-value = ',scales::scientific(pks,3),'\\n',\n                        'Real X importance values are greater than Permuted X importance values'))\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npks <- \n    ks.test(\n    reticulate::py$ppred_df %>% \n    filter(type=='real' & y_true==1) %>% \n    pull(y_proba),\n    reticulate::py$ppred_df %>% \n    filter(type=='permuted' & y_true==1) %>% \n    pull(y_proba)\n)[['p.value']]\npwilcox <- \n    wilcox.test(\n    reticulate::py$ppred_df %>% \n    filter(type=='real' & y_true==1) %>% \n    pull(y_proba),\n    reticulate::py$ppred_df %>% \n    filter(type=='permuted' & y_true==1) %>% \n    pull(y_proba)\n)[['p.value']]\n\nreticulate::py$ppred_df %>% \n    arrange(pt,bootstrap) %>%\n    ggplot(aes(y_proba,fill=factor(y_true),group=y_true)) +\n    geom_histogram(aes(y=after_stat(count)),alpha=.5,binwidth = .01) +\n    scale_fill_brewer(NULL,\n                      palette = 'Set1',\n                      direction = -1,\n                      labels=c(\"Class 0\",\"Class 1\"),\n                      guide=guide_legend(title=NULL)) +\n    facet_wrap(~type,ncol=1,scales='free') +\n    theme_bw() +\n    labs(x='Prediction Probability',\n         y='Number of Prediction Probabilities',\n         caption = paste0('Wilcox p-value = ',scales::scientific(pwilcox,3),'\\n',\n                          'Kolmogorov-Smirnov p-value = ',scales::scientific(pks,3),'\\n',\n                        'Real Class 1 probabilities are greater than Permuted Class 1 probabilities'))\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nThis next example shows high power \n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nN=100\nX1 = np.random.normal(loc=0,scale=1,size=N)\nX2 = np.random.normal(loc=2,scale=1,size=N)\nX = np.concatenate([X1,X2])\nY = np.concatenate([np.repeat(0,N),np.repeat(1,N)])\n\nimport pandas as pd\ndf = pd.DataFrame(data={'Y' : Y,'X' : X})\ndf.index.name = 'pt'\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndf <- reticulate::py$df\n\ndf[['Y']] <- factor(df$Y,levels=c(0,1))\n\ndf %>% \n    ggplot(aes(Y,X)) +\n    geom_boxplot(outlier.size = NA,alpha=0,linewidth=2) +\n    geom_point(position = position_jitter(width = .2),pch=21,fill='gray',size=3) +\n    labs(x = \"Response\",y=\"Predictor\",title = \"Predictor values for Class One are 200% larger on average\") +\n    theme_bw(base_size = 16)\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport mccv\n\nmccv_obj = mccv.mccv(num_bootstraps=200,n_jobs=4)\nmccv_obj.set_X(df[['X']])\nmccv_obj.set_Y(df[['Y']])\nmccv_obj.run_mccv()\nmccv_obj.mccv_data['Feature Importance'].insert(\n    len(mccv_obj.mccv_data['Feature Importance'].columns),\n    'type',\n    'real'\n)\nmccv_obj.mccv_data['Model Learning'].insert(\n    len(mccv_obj.mccv_data['Model Learning'].columns),\n    'type',\n    'real'\n)\nmccv_obj.mccv_data['Patient Predictions'].insert(\n    len(mccv_obj.mccv_data['Patient Predictions'].columns),\n    'type',\n    'real'\n)\nmccv_obj.run_permuted_mccv()\nmccv_obj.mccv_permuted_data['Feature Importance'].insert(\n    len(mccv_obj.mccv_permuted_data['Feature Importance'].columns),\n    'type',\n    'permuted'\n)\nmccv_obj.mccv_permuted_data['Model Learning'].insert(\n    len(mccv_obj.mccv_permuted_data['Model Learning'].columns),\n    'type',\n    'permuted'\n)\nmccv_obj.mccv_permuted_data['Patient Predictions'].insert(\n    len(mccv_obj.mccv_permuted_data['Patient Predictions'].columns),\n    'type',\n    'permuted'\n)\n\nfimp_df = \\\npd.concat([\n    (mccv_obj.mccv_data['Feature Importance'].\n    query('feature==\"X\"').\n    reset_index(drop=True)),\n    (mccv_obj.mccv_permuted_data['Feature Importance'].\n    query('feature==\"X\"').\n    reset_index(drop=True))\n])\nppred_df = \\\npd.concat([\n    (mccv_obj.mccv_data['Patient Predictions'].\n    drop('y_pred',axis=1).\n    reset_index()),\n    (mccv_obj.mccv_permuted_data['Patient Predictions'].\n    reset_index().\n    drop('y_pred',axis=1))\n])\npred_df = \\\npd.concat([\n    (mccv_obj.mccv_data['Model Learning'].\n    reset_index()),\n    (mccv_obj.mccv_permuted_data['Model Learning'].\n    reset_index())\n])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npks <- \n    ks.test(\n    reticulate::py$pred_df %>% \n        filter(type=='real') %>% \n        pull(validation_roc_auc),\n    reticulate::py$pred_df %>% \n        filter(type=='permuted') %>% \n        pull(validation_roc_auc),\n    alternative = 'greater'\n)[['p.value']]\n\npwilcox <- \n    wilcox.test(\n    reticulate::py$pred_df %>% \n        filter(type=='real') %>% \n        pull(validation_roc_auc),\n    reticulate::py$pred_df %>% \n        filter(type=='permuted') %>% \n        pull(validation_roc_auc)\n)[['p.value']]\n\nreticulate::py$pred_df %>% \n    ggplot(aes(validation_roc_auc,fill=type)) +\n    geom_histogram(aes(y=after_stat(count)),alpha=.5,binwidth = .05) +\n    scale_fill_brewer(palette = 'Set1',direction = -1,\n                      guide=guide_legend(title=NULL)) +\n    theme_bw() +\n    scale_x_continuous(\n        breaks=seq(0,1,0.05),\n    ) +\n    labs(x='Validation AUROC from Model Learning',\n         y='Number of Validation AUROC values',\n         caption=paste0('Wilcox p-value = ',scales::scientific(pwilcox,3),'\\n',\n                        'Kolmogorov-Smirnov p-value = ',scales::scientific(pks,3),'\\n',\n                        'Real validation AUROC values are greater than Permuted validation AUROC values'))\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npks <- \n    ks.test(\n    reticulate::py$fimp_df %>% \n        filter(type=='real') %>% \n        pull(importance),\n    reticulate::py$fimp_df %>% \n        filter(type=='permuted') %>% \n        pull(importance)\n)[['p.value']]\n\npwilcox <- \n    wilcox.test(\n    reticulate::py$fimp_df %>% \n        filter(type=='real') %>% \n        pull(importance),\n    reticulate::py$fimp_df %>% \n        filter(type=='permuted') %>% \n        pull(importance)\n)[['p.value']]\n\nreticulate::py$fimp_df %>% \n    ggplot(aes(importance,fill=type)) +\n    geom_histogram(aes(y=after_stat(count)),alpha=.5,binwidth = .2) +\n    scale_fill_brewer(palette = 'Set1',direction = -1,\n                      guide=guide_legend(title=NULL)) +\n    theme_bw() +\n    labs(x='Importance of X in Predicting Y',\n         y='Number of X importance values',\n         caption=paste0('Wilcox p-value = ',scales::scientific(pwilcox,3),'\\n',\n                        'Kolmogorov-Smirnov p-value = ',scales::scientific(pks,3),'\\n',\n                        'Real X importance values are greater than Permuted X importance values'))\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npks <- \n    ks.test(\n    reticulate::py$ppred_df %>% \n    filter(type=='real' & y_true==1) %>% \n    pull(y_proba),\n    reticulate::py$ppred_df %>% \n    filter(type=='permuted' & y_true==1) %>% \n    pull(y_proba)\n)[['p.value']]\npwilcox <- \n    wilcox.test(\n    reticulate::py$ppred_df %>% \n    filter(type=='real' & y_true==1) %>% \n    pull(y_proba),\n    reticulate::py$ppred_df %>% \n    filter(type=='permuted' & y_true==1) %>% \n    pull(y_proba)\n)[['p.value']]\n\nreticulate::py$ppred_df %>% \n    arrange(pt,bootstrap) %>%\n    ggplot(aes(y_proba,fill=factor(y_true),group=y_true)) +\n    geom_histogram(aes(y=after_stat(count)),alpha=.5,binwidth = .01) +\n    scale_fill_brewer(NULL,\n                      palette = 'Set1',\n                      direction = -1,\n                      labels=c(\"Class 0\",\"Class 1\"),\n                      guide=guide_legend(title=NULL)) +\n    facet_wrap(~type,ncol=1,scales='free') +\n    theme_bw() +\n    labs(x='Prediction Probability',\n         y='Number of Prediction Probabilities',\n         caption = paste0('Wilcox p-value = ',scales::scientific(pwilcox,3),'\\n',\n                          'Kolmogorov-Smirnov p-value = ',scales::scientific(pks,3),'\\n',\n                        'Real Class 1 probabilities are greater than Permuted Class 1 probabilities'))\n```\n\n::: {.cell-output-display}\n![](mccv_power_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\nThese two examples show different metrics for defining a 'powerful' prediction. Here, a powerful prediction can only be defined by the combination of different components to describe how and to what degree a predictor X can predict a response Y. These components can come from the model learning process as well as the applying the model on new data i.e. a validation set. Defining a powerful prediction is difficult using only one quantitative metric, like the statistical tests shown in the plot captions. But a few metrics noted here (and probably others I've mistakingly overlooked) can accurately define a powerful prediction:\n\n- The average AUROC for the validation set should be more than 50%. To be more strict, the 95% confidence interval should be greater than 50% AUROC.\n\n- The importance value (beta coefficient for logistic regression) of X for predicting Y should be above the null association i.e. 0 and should _barely_ overlap the importance values for a shuffled response. Statistical tests will probably produce a false positive by showing a small p-value, like here, so they shouldn't be *the* metric in defining a powerful prediction.\n\n- There seems to be at least two takeaways from the distributions of the prediction probabilities. First, the distribution of the real predicted probabilities for class 1 need to be greater than that for class 0. Also the distribution of real, class 1 predicted probabilities need to be greater than the distribution of permuted, class 1 predicted probabilities. \n\nI used a combination of the metrics referenced above in the papers published using MCCV. This article's toy examples illustrate why these metrics are sensible for defining the power of a prediction given the data. \n\n\n",
    "supporting": [
      "mccv_power_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}